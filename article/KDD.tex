\documentclass{article}
\usepackage{algorithm}
\usepackage{algorithmic}
\floatname{algorithm}{Procedure}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\newcommand{\cH}{\mathcal{H}}
\input{DataMining.tex}
\begin{document}
%%d : dimension
%%n : number of points
\section{Basic Concepts about Clustering}
\label{sec:BasicConceptsClustering}
Let $d$ be a positive integer and $\RR$ the field of real numbers.
For a set $\Set$ of $n$ points $\vec{p_i}\in \RR^d$, we denote by
$|\Set|$ the number of points of $\Set$. We consider the problem that
we will call  ``$\k$-means globally optimum clustering''.
\begin{definition}
  The ``$\k$-means globally optimum clustering'' is to split  
  $\Set\subset\RR^{d}$ of $n$ points $\vec{p_i}$, $i=1,\ldots, n$ into
  $\k$ disjoint 
  nonempty subsets $\Set_1,\ldots, \Set_{\k}$ called \textit{clusters}
  in such a way that the following expression is minimized:
  \begin{equation*}
    f_{\Set_1,\ldots,\Set_{\k}}(\Set)=\sum_{j=1}^\k \sum_{\vec{p} \in \Set_j}
    \norm{\vec{p}-\vec{q}_j}^2,\quad\text{where }
    \vec{q}_j = \frac{\sum_{\vec{p} \in \Set_j} \vec{p}}{|\Set_j|}.
  \end{equation*}
  $\Set_1,\ldots, \Set_{\k}$ is called an \textit{optimal partition}
  of $\Set.$
\end{definition}
It is well known that, given $\Set$, there always exists
$\vec{q_1},\ldots, \vec{q_k}$ such that the partition defined as,
\begin{multline*}
  \Set_j=\{\vec{p}\in\Set\ :\ 
  \|\vec{p}-\vec{q_j}\|^2< \|\vec{p}-\vec{q_l}\|^2,\; l =1,\ldots, j-1\\
  \text{ and }
  \|\vec{p}-\vec{q_j}\|^2\le \|\vec{p}-\vec{q_i}\|^2,\; i =j,\ldots, k \},
\end{multline*}
is an optimal partition.
Indeed, the common approach to attack this problem is to use 
\textit{Lloyd's heuristic}~\cite{Lloy82}, which basically tries to find 
$\vec{q_1},\ldots, \vec{q_k}$ through an iterative process.
Although the standard algorithm was presented in ~\cite{Lloy82},
the term $k-$means was first used in~\cite{MacQ67}  and, under minor
modifications, performs quite well in practice, see~~\cite{arthurVas07,ZhangXia09}.

We will need the following concepts from topology:
\begin{itemize}
\item A  set contained in $\RR^d$  is \textit{convex} if for any
  pair of points within the set, every point in the straight line
  segment that joins them is also within the object.
\item Given a set of points $\Set\subset\RR^{d}$, the convex hull of $\Set$ is the
  smallest convex set of $\RR^{d}$ which contains $\Set$.
\item   Given $\vec{a}\in\RR^d-\{\vec{0}\}$ and $b\in\RR$, the set 
  $\cH = \{\vec{x}\in\RR^d : \transpose{\vec{a}}\vec{x}=b\}$ is called
  a hyperplane.
\item A point $\vec{p}\in\RR^{d}$ lays in the \textit{left side} of
  hyperplane $\cH$ if $\transpose{\vec{a}}\vec{p}>b$. If 
  $\transpose{\vec{a}}\vec{p} < b$, the point $\vec{p}$ lays  in the
  \textit{right side} of hyperplane $\cH$.
\item An hyperplane $\cH$ \textit{separates} two sets $\Set,\
  \Set'\subset\RR^d$ if  the points in $\Set$ lays in the same side
  of $\cH$ and none the points in $\Set'$ lays in this side of
  $\cH$.
\item An hyperplane $\cH$ \textit{splits} a set $\Set$ if any point
  $\vec{p}\in\Set$ lays in the right or the left side of $\cH$. 
\end{itemize}
We cite here  the separating hyperplane theorem, 
see~\cite[page 46]{BoydLieven04} for a proof. 
\begin{lemma}
  \label{lem:maximum_separation}
  For any two convex sets $\Set,\ \Set'\subset \RR^d$ such that
  $\Set\cap \Set' =  \emptyset$,  there exists an   hyperplane $\cH$
  that separates $\Set$ and $\Set'$.
\end{lemma}

As it was stated before, it is known that one optimal partition can be
defined using 
$k$ points of $\RR^d$, called \textit{centroids}. Partitions using
centroids have a very interesting property.
\begin{lemma}
  Given a set of point $\Set\subset \RR^{d}$ and
  $\vec{q_1},\ldots,\vec{q_k}\in\RR^d$, the partition $\Set_1,\ldots,
  \Set_k$ defined as 
  \begin{multline*}
  \Set_j=\{\vec{p}\in\Set\ :\ 
  \|\vec{p}-\vec{q_j}\|^2< \|\vec{p}-\vec{q_l}\|^2,\; l =1,\ldots, j-1\\
  \text{ and }
  \|\vec{p}-\vec{q_j}\|^2\le \|\vec{p}-\vec{q_i}\|^2,\; i =j,\ldots, k \},
  \end{multline*}
  for $j = 1,\ldots, k$ satisfies:
  \begin{itemize}
  \item the intersection of the convex hull of any two different
    clusters $\Set_i,\Set_j$ is empty,
  \item for each pair $\Set_i, \Set_j$ exists an hyperplane $\cH$ that 
    separates $\Set_i$ and $\Set_j$.
  \end{itemize}
\end{lemma}
\begin{proof}
  The first assertion of the lemma is proved by induction on $k$. For
  $k=2$, consider the following sets,
  \begin{equation*}
    \bSet_1 = \{\vec{p}\in\RR^{d}\; :\;  \|\vec{p}-\vec{q_1}\|^2\le
    \|\vec{p}-\vec{q_2}\|^2\},\quad
     \bSet_2 = \{\vec{p}\in\RR^{d}\; :\;  \|\vec{p}-\vec{q_1}\|^2>
    \|\vec{p}-\vec{q_2}\|^2\}.
  \end{equation*}
  It is trivial that both sets are convex, the intersection is empty
  and they contain 
  $\Set_1,\Set_2$, respectively. By the definition of convex hull,
  $\bSet_1,\bSet_2$ must contain the convex hull of
  $\Set_1,\Set_2$ and this finishes the proof for $k=2$.

  The general case is proved in a similar way  noting that the intersection
  of two convex sets is a convex set. So, the convex hull of 
  \begin{multline*}
  \Set_j=\{\vec{p}\in\Set\ :\ 
  \|\vec{p}-\vec{q_j}\|^2< \|\vec{p}-\vec{q_l}\|^2,\; l =1,\ldots, j-1\\
  \text{ and }
  \|\vec{p}-\vec{q_j}\|^2\le \|\vec{p}-\vec{q_i}\|^2,\; i =j,\ldots, k \},
  \end{multline*}
  is contained in the following set
  \begin{multline*}
    \bSet_j=\{\vec{p}\in\RR^{d}\ :\
    \|\vec{p}-\vec{q_j}\|^2< \|\vec{p}-\vec{q_l}\|^2,\; l =1,\ldots, j-1\\
    \text{ and } \|\vec{p}-\vec{q_j}\|^2\le \|\vec{p}-\vec{q_i}\|^2,\;
    i =j,\ldots, k \}.
  \end{multline*}
  Again, it is easy to check that $\bSet_j\cap \bSet_l=\emptyset$ for
  $l\neq j$ and each of these sets can be put as an intersection of
  convex sets. The rest of the proof of this item is straightforward.

  The second assertion is a direct application of
  Lemma~\ref{lem:maximum_separation} and that $\bSet_j$ is a family of
  convex sets with empty intersection.
\end{proof}

\section{Reverse Enumeration}
\label{sec:reverse_enumeration}
Reverse Enumeration is a method for listing objects that satisfy a
specific property. It was introduced in~\cite{AvisFukuda} to solve
the following problem,
\begin{problem}
  \label{prob:traversal}
  Suppose that $G = (V, E)$ be an undirected graph, where $V$ is a set
  of vertex and $E$ is the edge set. Enumerate all the elements in $V$. 
\end{problem}
The difficulty of this particular problem lays in the fact that $V$
is  not given explicitly, however given a node $v\in V$ it is possible
to calculate its neighbors.

The problem of graph traversal is well-known, and there are 
several algorithms like breadth-first search and depth-first
search, see~\cite[Page 597]{Cormen}. 

Unfortunately, these algorithms needs to mantain a data 
structure with all the nodes that have been visited in order to avoid
looping endlessly in a cycle of the graph. This implies a big
drawback in terms of memory usage. 
  
For introducing a more efficient way of solving
Problem~\ref{prob:traversal} we need to introduce the definition of
\textit{local search}. 
\begin{definition}
  A local search  $(G, R, f)$ is a triple satisfying $R\subset V$, $f$
  is  a mapping $f: V\mapsto V$ with the following properties:
  \begin{itemize}
  \item $(v,f(v))$ is an edge of the graph for $v\in V- R$,
  \item for all $v\in  V- R$, there exists a positive integer $t$
    depending on $v$ such
    that $f^{t}(v)\in R$.
  \end{itemize}
  The function $f$ is said to be the \textit{local search function}, 
  $R$  the set of solutions
  and $G$  the \textit{underlaying graph structure}.
\end{definition}
Informally a local search algorithm is a way of explore a
graph in a  non systematic way, starting in any candidate and heading
for the set of solutions $R$,  see~\cite[Page 110]{RussellNorvig} for
a more detailed exposition.  

A local search define a subgraph of $G$ called the \textit{trace} $T =
(V, E(f))$ where,
\begin{equation*}
  E(f) = \{(v,f(v)\ :\ v\in V- R\}.
\end{equation*}
An important fact that appear in~\cite[Property 2.1]{AvisFukuda} is
that the trace of any local search contains all the nodes of $G$ and
each component contains only one element of the set $R$ and no
cycles. 

So, most efficient way to output all the component is to traverse all
the components of $T$, starting at every element of $R$. 
However, to do so, it is necessary to invert $f$, i. e. 
given $v$, find all the elements $v'$, such that $f(v')=v$. For a
general local search function $f$ is normally difficult to find 
the preimages of a node $v$. In most of the cases where reverse
enumeration is useful, there is an 
\textit{adjacency oracle} which gives the neighbours of a node. The
original definition can be found in~\cite{AvisFukuda}, but here we
simplify it for our purposes. 
\begin{definition}
  A graph $G$ is given by an  adjacency oracle if there exists  a
  function $Adj$ that takes a node $v$ an return an ordered list of
  neighbors of $v$.
\end{definition}
So, given a graph $G$ given by an adjacency oracle $Adj$ and a local
search $(G,R,f)$, Algorithm~\ref{alg:reverse_enumeration} will output
all the nodes. 
\begin{algorithm}
  \caption{General Reverse Search}
  \label{alg:reverse_enumeration}
  \begin{algorithmic}
    \REQUIRE An adjacency oracle $Adj$, a local search $(G,R,f)$
    \ENSURE all nodes in $V$ without any repetition
    \FORALL{$r\in R$}
    \STATE yield $r$
    \STATE {$i, do, v = 1, True, r$}
    \WHILE{$do$}
    \WHILE{ there are at least $i$ elements in $Adj(v)$}
    \STATE let $Next$ be the $i$th element of $Adj(v)$
    \IF{$f(Next) == v$}
    \STATE $v, i = Next, 0$
    \ELSE
    \STATE { $i = i +1$}
    \ENDIF
    \ENDWHILE
    \IF{$v == r$}
    \STATE{$do = False$}
    \ELSE
    \STATE $u, v, i  = v, f(v), 1$
    \WHILE{$i$th element of $Adj(v)$ is not $u$}
    \STATE $i = i +1$
    \ENDWHILE
    \ENDIF
    \ENDWHILE
    \ENDFOR
  \end{algorithmic}
\end{algorithm}
The complexity of the algorithm is given in~\cite[Theorem
2.2]{AvisFukuda}, which we enunciate here.
\begin{theorem}
  Let   $(G, R, f)$ be a local search where  $G$ is
  given by a adjacency oracle $Adj$. Suppose that  $Adj(v)$ does not
  contain more than $\delta$ nodes for any $v\in V$. Then, if $t(f)$
  and $t(Adj)$ are the times complexity for $f$ and $Adj$,
  respectively, the time complexity of reverse search is of order of
  magnitude, 
  \begin{equation*}
    \delta t(Adj)|V| + t(f)|E|.
  \end{equation*}
\end{theorem}
In the next subsections, we show how to apply reverse search for the
problem of enumerating all possible partitions defined by centroids.
\subsection{Reverse search for two clustering problem}
\label{sec:two_clusters}
In order  to adapt reverse
search for the problem of enumerating all possible partitions defined
by two clusters, we need to define the
following objects:
\begin{itemize}
\item the graph $G = (V, E)$,
\item a local search $(G, R, f)$,
\item an adjacency oracle $Adj$.
\end{itemize}
$V$ is a complete description of all possible ways to split $\Set$ by
hyperplanes.
It is represented by a set of hyperplanes satisfying two
properties:
\begin{itemize}
\item each of the hyperplanes splits the set $\Set$ in a different
  way.
\item If $\Set_1$ and $\Set_2$ is a partition of $\Set$ and the
  intersection of the convex hulls of $\Set_1$
  and $\Set_2$ is empty, then there exists an hyperplane $\cH\in V$
  which separates $\Set_1$ and $\Set_2$.
\end{itemize}
In other words, $V$ is a set of representatives of all possible
partitions into two clusters given by hyperplanes. 

Now, we define the set $E$ implicitly by defining when two nodes are
neighbors. 
Two hyperplanes $\cH,\cH'\in V$ are neighbours in graph $G$ if and
only if the points of $\Set$ that  lay in the left side of $\cH$ are
exactly the points that lay in the left side of $\cH$, except for one
point in $\Set$. Informally, two nodes are neighbors if the partitions they
defined are the same except from one point.

\subsubsection{Local search}
\label{sec:sub_local_search}
The local search is an important part in the efficiency of the
algorithm. For the rest of the paper, we suppose that points in $\Set$
are ordered, so $\Set = \{\vec{p}_1,\ldots,\vec{p}_n \}$. One possible
local search function is given in Algorithm~\ref{alg:naive}.
 \begin{algorithm}
  \caption{naive local search function f}
  \label{alg:naive}
  \begin{algorithmic}
  \REQUIRE an hyperplane $\cH$
  \STATE Let $\Set_1$ and $\Set_2$ the partition defined by $\cH$
  \FORALL{$\vec{p}$ in $\Set_2$}
  \IF{There exists an hyperplane $\cH'$ that separate $\Set_1\cup
    \{\vec{p}\}$ and $\Set_2 -\{\vec{p}\}$}
  \RETURN $\cH'$
  \ENDIF
  \ENDFOR
  \RETURN $\cH$
  \end{algorithmic}
\end{algorithm}
The set $R = \{\cR\}$ contains only an hyperplane $\cR$ with
the property that all the points lay in the left side of this
hyperplane.

The problem with this proposal is that it is necessary to find an
hyperplanes that separates two sets of points and this can be quite
expensive in term of time, see~\cite{Elizondo06}. 
We adapt the proposal for the local search $(G, R, f)$ 
in~\cite{SleumerMsc} because it is more efficient and only requires to
find a separating hyperplane. Unlike Algorithm~\ref{alg:naive}, this
local search function depends on $\vec{r}$.
\begin{algorithm}
  \caption{local search function f}
  \label{alg:sleumer}
  \begin{algorithmic}
  \REQUIRE An hyperplane $\cH$ which separates $\Set$ and the
  hyperplane $\cR$
  \ENSURE An hyperplane $\cH'$ which splits $\Set$
  \STATE $\vec{p}_{min}=\vec{p}_1$
  \FORALL{$\vec{p_k}$  in $\Set$}
  \IF{$\vec{p}_k$==$MinDistance(\vec{p}_{min}, \vec{p}_k,\cH,\vec{r})$}
  \STATE $\vec{p}_{min}=\vec{p}_1$
  \ENDIF
  \ENDFOR
  \STATE Let $\Set_1$ be the points laying at the left side of $\cH$ 
  \STATE Let $\Set_2$ be the points laying at the right side of $\cH$
  \RETURN An hyperplane separating $\Set_1\cup \{\vec{p}_{min}\}$ and 
  $\Set_2 - \{\vec{p}_{min}\}$
  \end{algorithmic}
\end{algorithm}
Although in a   cryptic way, this function takes the point in the right
side of $\cH$ that is the closest to hyperplane $\cH$ and then search
for an hyperplane that separates the points of left side plus this
one and the ones in the right side minus this point.
\begin{algorithm}
  \caption{Algorithm MinDistance}
  \begin{algorithmic}
  \REQUIRE Two hyperplanes $h_1,h_2$ and two different 
  points $\vec{p},\vec{r}$
  \ENSURE the hyperplane which intersects the segment closest to $\vec{p}$ 
  \STATE
  \begin{equation*}
    c_1=\frac{-\dotProd{h_1}{\vec{p}}}{\dotProd{h_1}{(\vec{r}-\vec{p})}},
    \quad c_2=
    \frac{-\dotProd{h_2}{\vec{p}}}{\dotProd{h_2}{(\vec{r}-\vec{p})}}
  \end{equation*}
  \IF {$c_1>c_2$}
  \STATE return $h_2$
  \ELSIF{$c_1<c_2$}
  \STATE return $h_1$
  \ELSE
  \STATE returns the minimum of $-h_1/\dotProd{h_1}{\vec{p}}$ and 
  $-h_2/\dotProd{h_2}{\vec{p}}$ by the lexicographic order.
  \ENDIF
  \end{algorithmic}
\end{algorithm} 

\subsubsection{The adjacency oracle}

The adjacency oracle is just an algorithm which that returns which
partitions are adjacents. Two partitions are adjacent if they differ
in only one point. This is equivalent to give which points are
vertices of the convex hull of each of the clusters. 
To know if a point is a vertices of the convex hull, it is only to 
solve the following linear program,
\begin{eqnarray*}
  \text{maximize }&\dotProd{\vec{p}}{\vec{x}},\\
  \text{subject to}&\dotProd{\mat{A}}{\vec{x}}\le \vec{b},\\
  &\dotProd{\vec{p}}{\vec{x}}\le t+1.\\
\end{eqnarray*}
If the value is strictly greater than $t$, then the point is a
vertices of the convex hull.
\bibliographystyle{plain}
\bibliography{bibliography}
\end{document}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
